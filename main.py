import os
import json
import time
import requests
import feedparser
from datetime import datetime
import re
import urllib.parse
from bs4 import BeautifulSoup
from dotenv import load_dotenv

load_dotenv()

GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL')

# 1. í•´ì™¸ ë‰´ìŠ¤ (êµ¬ê¸€ ë‰´ìŠ¤ RSS - ë‹¤êµ­ì–´/ê¸€ë¡œë²Œ)
# ì˜ì–´ ì¿¼ë¦¬ì§€ë§Œ, ê°êµ­ êµ¬ê¸€ ë‰´ìŠ¤ ì—ë””ì…˜ì— ë˜ì§€ë©´ í•´ë‹¹ êµ­ê°€ì˜ ê´€ë ¨ ê¸°ì‚¬(ìêµ­ì–´ í¬í•¨)ê°€ ë‚˜ì˜´
RSS_QUERIES_GLOBAL = [
    "Artificial Intelligence business", # AI ë¹„ì¦ˆë‹ˆìŠ¤
    "Sports technology startups",       # ìŠ¤í¬ì¸  í…Œí¬
    "Football analytics",               # ì¶•êµ¬ ë¶„ì„
    "Generative AI trends"              # ìƒì„±í˜• AI
]

# 2. êµ­ë‚´ ì •ì±… ë‰´ìŠ¤ (êµ¬ê¸€ ë‰´ìŠ¤ RSS - í•œêµ­ì–´/Domestic Policy)
RSS_QUERIES_KR_POLICY = [
    "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ AI ì‚°ì—… ìœ¡ì„±",
    "ë²”ì •ë¶€ AI êµ­ê°€ì „ëµ",
    "ë¬¸í™”ì²´ìœ¡ê´€ê´‘ë¶€ ìŠ¤í¬ì¸ ì‚°ì—… ì§€ì›",
    "ìŠ¤í¬ì¸  í…Œí¬ íˆ¬ì í€ë“œ ì •ì±…",
    "ë°ì´í„° ì‚°ì—… ì§„í¥ ë¡œë“œë§µ"
]

# 3. êµ­ë‚´ ì¼ë°˜ ë‰´ìŠ¤ (ë„¤ì´ë²„ ë‰´ìŠ¤ ì„¹ì…˜ ìŠ¤í¬ë˜í•‘)
NAVER_SECTIONS = [
    {"id": "105", "name": "IT/ê³¼í•™"},
    {"id": "101", "name": "ê²½ì œ"}
]

# êµ­ê°€ë³„ êµ¬ê¸€ ë‰´ìŠ¤ ì„¤ì •
REGION_CONFIGS = {
    'US': {'gl': 'US', 'hl': 'en-US', 'ceid': 'US:en', 'name': 'ë¯¸êµ­/ê¸€ë¡œë²Œ'},
    'GB': {'gl': 'GB', 'hl': 'en-GB', 'ceid': 'GB:en', 'name': 'ì˜êµ­/ìœ ëŸ½'},
    'JP': {'gl': 'JP', 'hl': 'ja',    'ceid': 'JP:ja', 'name': 'ì¼ë³¸'},
    'HK': {'gl': 'HK', 'hl': 'en-HK', 'ceid': 'HK:en', 'name': 'ì¤‘êµ­/ì•„ì‹œì•„'} # ì¤‘êµ­ ë³¸í†  ëŒ€ìš©
}

def get_google_news_rss_url(query, region_code='US'):
    """êµ¬ê¸€ ë‰´ìŠ¤ RSS URL ìƒì„± (êµ­ê°€ë³„ ì„¤ì • ì ìš©)"""
    encoded_query = urllib.parse.quote(query)
    config = REGION_CONFIGS.get(region_code, REGION_CONFIGS['US'])
    
    base_url = f"https://news.google.com/rss/search?q={encoded_query}&hl={config['hl']}&gl={config['gl']}&ceid={config['ceid']}"
    return base_url, config['name']

def fetch_google_rss_items(queries, target_regions=['US'], source_label_prefix="[í•´ì™¸]"):
    """êµ¬ê¸€ RSS ê¸°ë°˜ ë‰´ìŠ¤ ìˆ˜ì§‘ (ë‹¤ì¤‘ êµ­ê°€ ì§€ì›)"""
    items = []
    seen_links = set()
    
    for region in target_regions:
        print(f"ğŸ“¡ {source_label_prefix} ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... (Region: {region})")
        for query in queries:
            url, region_name = get_google_news_rss_url(query, region)
            try:
                feed = feedparser.parse(url)
                # í‚¤ì›Œë“œë³„ ìƒìœ„ ê°œìˆ˜ ì¡°ì ˆ (ë¯¸êµ­ ë¹„ì¤‘ í™•ëŒ€)
                limit = 8 if region == 'US' else 3 
                for entry in feed.entries[:limit]:
                    if entry.link not in seen_links:
                        items.append({
                            "title": entry.title,
                            "link": entry.link,
                            "source": f"{source_label_prefix} {region_name} (Google)",
                            "snippet": entry.get("description", "")[:200]
                        })
                        seen_links.add(entry.link)
            except Exception as e:
                print(f"Error fetching RSS for {query} in {region}: {e}")
            
    return items

def fetch_naver_news():
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ì„¹ì…˜ í¬ë¡¤ë§ (IT/ê³¼í•™, ê²½ì œ)"""
    items = []
    seen_links = set()
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    print("ğŸ“¡ [êµ­ë‚´] ë„¤ì´ë²„ ë‰´ìŠ¤(IT/ê²½ì œ) ìˆ˜ì§‘ ì¤‘...")
    
    for section in NAVER_SECTIONS:
        url = f"https://news.naver.com/section/{section['id']}"
        try:
            response = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            links = soup.find_all("a", href=True)
            
            count = 0
            for link in links:
                href = link['href']
                title = link.get_text(strip=True)
                
                if "/mnews/article/" in href and title and len(title) > 10:
                    if href not in seen_links:
                        items.append({
                            "title": title,
                            "link": href,
                            "source": f"Naver News ({section['name']})",
                            "snippet": "" 
                        })
                        seen_links.add(href)
                        count += 1
                        if count >= 8: # ì„¹ì…˜ë‹¹ ê°œìˆ˜ ì¡°ì ˆ
                            break
        except Exception as e:
            print(f"Naver Fetch Error ({section['name']}): {e}")
            
    return items

def get_usable_model_name():
    """APIì— ì§ì ‘ ë¬¼ì–´ë´ì„œ ì§„ì§œë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={GEMINI_API_KEY}"
    
    try:
        response = requests.get(url)
        if response.status_code != 200:
            print(f"âš ï¸ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {response.text}")
            return None
            
        data = response.json()
        if 'models' not in data:
            print("âš ï¸ ëª¨ë¸ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì°¾ê¸°
        candidates = []
        for model in data['models']:
            name = model['name'].replace('models/', '')
            methods = model.get('supportedGenerationMethods', [])
            
            if 'generateContent' in methods:
                candidates.append(name)
        
        print(f"ğŸ“‹ ë‚´ í‚¤ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëª¨ë¸ë“¤: {candidates}")
        
        preferred = [
            'gemini-1.5-flash',
            'gemini-1.5-flash-latest',
            'gemini-1.5-pro',
            'gemini-1.0-pro',
            'gemini-pro'
        ]
        
        for p in preferred:
            if p in candidates:
                return p
                
        # ì°¨ì„ ì±…
        for c in candidates:
            if 'gemini' in c and 'vision' not in c:
                return c
                
        if candidates:
            return candidates[0]
            
        return None

    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def analyze_and_filter_news(news_items):
    if not news_items:
        return []

    print(f"ğŸ§  ì´ {len(news_items)}ê°œì˜ í›„ë³´ ê¸°ì‚¬ ë¶„ì„ ë° ì„ ë³„ ì¤‘...")
    
    # ë™ì ìœ¼ë¡œ ëª¨ë¸ ì°¾ê¸°
    model_name = get_usable_model_name()
    if not model_name:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì§€ ëª»í•´ ê¸°ë³¸ê°’(gemini-pro)ìœ¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
        model_name = "gemini-pro"
        
    print(f"âœ¨ ì„ íƒëœ ëª¨ë¸: {model_name}")
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={GEMINI_API_KEY}"
    headers = {'Content-Type': 'application/json'}
    
    # í† í° ì ˆì•½ì„ ìœ„í•œ ê°„ì†Œí™”
    simplified_items = []
    for item in news_items:
        simplified_items.append({
            "t": item['title'],
            "l": item['link'],
            "s": item['source']
        })
        
    news_text = json.dumps(simplified_items, ensure_ascii=False)
    
    prompt = f"""
    ë„ˆëŠ” 'AI ì‚°ì—… ì „ë°˜'ê³¼ 'ìŠ¤í¬ì¸  ë¹„ì¦ˆë‹ˆìŠ¤'ë¥¼ ëª¨ë‘ ë‹¤ë£¨ëŠ” ìŠ¤íƒ€íŠ¸ì—…ì˜ ë¦¬ì„œì¹˜ íŒ€ì¥ì´ì•¼.
    ìš°ë¦¬ëŠ” ë„ˆë¬´ ì—„ê²©í•œ ê¸°ì¤€ë³´ë‹¤ëŠ”, **ë„“ì€ ì‹œì•¼ì˜ ì‚°ì—… ë™í–¥**ì„ íŒŒì•…í•˜ê³  ì‹¶ì–´.
    
    ì œê³µëœ ë‰´ìŠ¤ í›„ë³´êµ°(JSON)ì—ì„œ ìš°ë¦¬ì—ê²Œ ë„ì›€ì´ ë  ë§Œí•œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•´ì¤˜.

    [í›„ë³´êµ° ë°ì´í„°]:
    {news_text}

    [ì„ ë³„ ê¸°ì¤€ (ìƒë‹¹íˆ ê´€ëŒ€í•˜ê²Œ ì ìš©)]:
    1. **ì§€ì—­ ìš°ì„ ìˆœìœ„**: **[í•´ì™¸] ë¯¸êµ­/ê¸€ë¡œë²Œ ë‰´ìŠ¤**ëŠ” ê°€ì¥ ì„ ì§„ì ì¸ íŠ¸ë Œë“œì´ë¯€ë¡œ **ë°˜ë“œì‹œ 3ê°œ ì´ìƒ í¬í•¨**í•˜ë„ë¡ ë…¸ë ¥í•´. ì˜êµ­/ì¼ë³¸/ì¤‘êµ­ ë‰´ìŠ¤ëŠ” ì •ë§ ì¤‘ìš”í•œ ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ í¬í•¨í•´(ì—†ìœ¼ë©´ ê³¼ê°íˆ ìƒëµ).
    2. **ì •ë¶€ ì •ì±…**: í•œêµ­ ì •ë¶€(ê³¼ê¸°ë¶€/ë¬¸ì²´ë¶€)ì˜ ì§€ì› ì‚¬ì—…/ì •ì±…ì€ ë°œê²¬ ì¦‰ì‹œ **ë¬´ì¡°ê±´ í¬í•¨**.
    3. **ì‚°ì—… ë¶„ì•¼**: AI(ë¹„ì£¼ì–¼, ìƒì„±í˜•, ë¡œë´‡, ë°˜ë„ì²´) ë° ìŠ¤í¬ì¸  ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë°˜.
    4. **ì œì™¸ ëŒ€ìƒ**: ì˜¤ì§ 'ë‹¨ìˆœ ê²½ê¸° ìŠ¤ì½”ì–´(ëˆ„ê°€ ì´ê²¼ë‹¤)'ì™€ 'ì—°ì˜ˆì¸ ê°€ì‹­'ë§Œ ì œì™¸í•´.

    [ì‘ì„± ì§€ì¹¨]:
    - **ìˆ˜ëŸ‰**: **ìµœì†Œ 5ê°œ ~ ìµœëŒ€ 10ê°œ**. (ê¸°ì¤€ì´ ì¡°ê¸ˆ ì• ë§¤í•´ë„ ì—°ê´€ì„± ìˆìœ¼ë©´ ê³¼ê°í•˜ê²Œ í¬í•¨í•´ì„œ ê°œìˆ˜ë¥¼ ì±„ìš¸ ê²ƒ!)
    - **ì–¸ì–´**: í•´ì™¸ ë‰´ìŠ¤ëŠ” ë°˜ë“œì‹œ **í•œêµ­ì–´ë¡œ ë²ˆì—­**í•´ì„œ ìš”ì•½.
    - **ìš”ì•½**: "ê´€ë ¨ ì‚°ì—…êµ°ì— ê¸ì •ì /ë¶€ì •ì  ìš”ì¸ìœ¼ë¡œ ì‘ìš©í•  ì˜ˆì •" ë“±ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ í†¤ì•¤ë§¤ë„ˆ.

    [ì¶œë ¥ í¬ë§· - JSON Array Only]:
    [
      {{
        "title": "ê¸°ì‚¬ ì œëª©",
        "summary": "í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (í•œêµ­ì–´)",
        "original_link": "ë§í¬",
        "source": "ì¶œì²˜ í‘œê¸°"
      }}
    ]
    """
    
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            text = response.json().get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '[]')
            clean_text = re.sub(r"```json|```", "", text).strip()
            
            # ë””ë²„ê¹…: ì›ë³¸ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì´ìƒí•˜ë©´ ì¶œë ¥
            if len(clean_text) < 10:
                print(f"âš ï¸ Gemini ì‘ë‹µì´ ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ìŒ: {clean_text}")

            # JSON íŒŒì‹± ì‹œë„ (ëŒ€ê´„í˜¸ ì°¾ê¸°)
            match = re.search(r'\[.*\]', clean_text, re.DOTALL)
            final_text = match.group(0) if match else clean_text
            
            try:
                result = json.loads(final_text)
                if not result:
                    print(f"âš ï¸ Geminiê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸([])ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ í…ìŠ¤íŠ¸:\n{text[:500]}...")
                return result
            except json.JSONDecodeError as je:
                print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ:\n{text}")
                return []
                
        else:
            print(f"Gemini API Error Status: {response.status_code} - {response.text}")
            
    except Exception as e:
        print(f"Gemini API Request Error: {e}")
        return []
    
    return []

def send_discord_report(news_list):
    if not DISCORD_WEBHOOK_URL:
        print("ë””ìŠ¤ì½”ë“œ ì›¹í›… URL ì—†ìŒ")
        return
    if not news_list:
        print("ì „ì†¡í•  ë‰´ìŠ¤ê°€ ì—†ìŒ")
        return

    today = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    
    embed = {
        "title": f"ğŸ“° {today} AIÂ·ìŠ¤í¬ì¸  ìŠ¤íƒ€íŠ¸ì—… ë°ì¼ë¦¬ ë¸Œë¦¬í•‘",
        "description": "êµ­ë‚´ì™¸ ì‚°ì—… ë™í–¥ ë° ì£¼ìš” ì •ë¶€ ì •ì±… ëª¨ë‹ˆí„°ë§",
        "color": 0x00ff00,
        "fields": [],
        "footer": {
            "text": "Powered by Gemini Agent",
        }
    }
    
    for news in news_list:
        # ì†ŒìŠ¤ì— ë”°ë¼ ì•„ì´ì½˜ì´ë‚˜ íƒœê·¸ë¥¼ ë‹¤ë¥´ê²Œ í•  ìˆ˜ë„ ìˆìŒ
        source_display = news.get('source', 'ë‰´ìŠ¤')
        # AIê°€ sourceë¥¼ ë®ì–´ì“°ì§€ ì•Šì•˜ë‹¤ë©´ ì›ë³¸ source ì‚¬ìš©
        if '[' not in source_display and 'Google' in source_display and 'KR' in source_display:
             source_display = "[ì •ì±…]"
        elif '[' not in source_display and 'Google' in source_display:
             source_display = "[í•´ì™¸]"
        elif '[' not in source_display and 'Naver' in source_display:
             source_display = "[êµ­ë‚´]"
             
        embed["fields"].append({
            "name": f"{source_display} {news['title']}",
            "value": f"{news['summary']}\n[ğŸ”— ê¸°ì‚¬ ì½ê¸°]({news['original_link']})",
            "inline": False
        })
        
    payload = {"embeds": [embed]}
    
    try:
        requests.post(DISCORD_WEBHOOK_URL, json=payload)
        print("âœ… ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì™„ë£Œ")
    except Exception as e:
        print(f"ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    # 1. ìˆ˜ì§‘
    
    # 1-1. í•´ì™¸ (ë¯¸êµ­, ìœ ëŸ½, ì¼ë³¸, ì•„ì‹œì•„)
    # ì˜ì–´ ì¿¼ë¦¬ë¥¼ ê°êµ­ êµ¬ê¸€ ë‰´ìŠ¤ì— ë˜ì ¸ì„œ ì§€ì—­ë³„ ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘ (ì¼ë³¸ì€ ì¼ì–´ ê¸°ì‚¬ë„ ì¡í˜)
    overseas_items = fetch_google_rss_items(
        RSS_QUERIES_GLOBAL, 
        target_regions=['US', 'GB', 'JP', 'HK'], 
        source_label_prefix="[í•´ì™¸]"
    )
    
    # 1-2. êµ­ë‚´ ì •ì±… (í•œêµ­ì–´ í‚¤ì›Œë“œ - í•œêµ­ ë¦¬ì „ ê³ ì •)
    # fetch_google_rss_items ì¬í™œìš©
    REGION_CONFIGS['KR'] = {'gl': 'KR', 'hl': 'ko', 'ceid': 'KR:ko', 'name': 'í•œêµ­/ì •ì±…'}
    
    policy_items = fetch_google_rss_items(
        RSS_QUERIES_KR_POLICY, 
        target_regions=['KR'], 
        source_label_prefix="[ì •ì±…]"
    )
    
    # 1-3. êµ­ë‚´ ì¼ë°˜ (ë„¤ì´ë²„ ì„¹ì…˜)
    domestic_items = fetch_naver_news()
    
    all_items = overseas_items + policy_items + domestic_items
    
    if all_items:
        # 2. ë¶„ì„
        print(f"ğŸ“¦ ì´ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ í›„ë³´: {len(all_items)}ê°œ")
        selected = analyze_and_filter_news(all_items)
        if selected:
            print(f"ğŸ‘‰ ìµœì¢… ì„ ë³„ëœ ë‰´ìŠ¤: {len(selected)}ê±´")
            send_discord_report(selected)
        else:
            print("ğŸ¤” ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ì–´ ì „ì†¡í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
