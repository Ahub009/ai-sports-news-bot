import os
import json
import time
import requests
import feedparser
from datetime import datetime
import re
import urllib.parse
from bs4 import BeautifulSoup
from dotenv import load_dotenv

load_dotenv()

GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL')

# 1. í•´ì™¸ ë‰´ìŠ¤ (êµ¬ê¸€ ë‰´ìŠ¤ RSS - ë‹¤êµ­ì–´/ê¸€ë¡œë²Œ)
# ì˜ì–´ ì¿¼ë¦¬ì§€ë§Œ, ê°êµ­ êµ¬ê¸€ ë‰´ìŠ¤ ì—ë””ì…˜ì— ë˜ì§€ë©´ í•´ë‹¹ êµ­ê°€ì˜ ê´€ë ¨ ê¸°ì‚¬(ìêµ­ì–´ í¬í•¨)ê°€ ë‚˜ì˜´
RSS_QUERIES_GLOBAL = [
    "Artificial Intelligence business", # AI ë¹„ì¦ˆë‹ˆìŠ¤
    "Sports technology startups",       # ìŠ¤í¬ì¸  í…Œí¬
    "Football analytics",               # ì¶•êµ¬ ë¶„ì„
    "Generative AI trends"              # ìƒì„±í˜• AI
]

# 2. êµ­ë‚´ ì •ì±… ë‰´ìŠ¤ (êµ¬ê¸€ ë‰´ìŠ¤ RSS - í•œêµ­ì–´/Domestic Policy)
RSS_QUERIES_KR_POLICY = [
    "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ AI ì‚°ì—… ìœ¡ì„±",
    "ë²”ì •ë¶€ AI êµ­ê°€ì „ëµ",
    "ë¬¸í™”ì²´ìœ¡ê´€ê´‘ë¶€ ìŠ¤í¬ì¸ ì‚°ì—… ì§€ì›",
    "ìŠ¤í¬ì¸  í…Œí¬ íˆ¬ì í€ë“œ ì •ì±…",
    "ë°ì´í„° ì‚°ì—… ì§„í¥ ë¡œë“œë§µ"
]

# 3. êµ­ë‚´ ì¼ë°˜ ë‰´ìŠ¤ (ë„¤ì´ë²„ ë‰´ìŠ¤ ì„¹ì…˜ ìŠ¤í¬ë˜í•‘)
NAVER_SECTIONS = [
    {"id": "100", "name": "ì •ì¹˜"},    # Politics (Policy)
    {"id": "105", "name": "IT/ê³¼í•™"}, # Science/IT
    {"id": "101", "name": "ê²½ì œ"}     # Economy
]

# êµ­ê°€ë³„ êµ¬ê¸€ ë‰´ìŠ¤ ì„¤ì •
REGION_CONFIGS = {
    'US': {'gl': 'US', 'hl': 'en-US', 'ceid': 'US:en', 'name': 'ë¯¸êµ­/ê¸€ë¡œë²Œ'},
    'GB': {'gl': 'GB', 'hl': 'en-GB', 'ceid': 'GB:en', 'name': 'ì˜êµ­/ìœ ëŸ½'},
    'JP': {'gl': 'JP', 'hl': 'ja',    'ceid': 'JP:ja', 'name': 'ì¼ë³¸'},
    'HK': {'gl': 'HK', 'hl': 'en-HK', 'ceid': 'HK:en', 'name': 'ì¤‘êµ­/ì•„ì‹œì•„'} # ì¤‘êµ­ ë³¸í†  ëŒ€ìš©
}

def get_google_news_rss_url(query, region_code='US'):
    """êµ¬ê¸€ ë‰´ìŠ¤ RSS URL ìƒì„± (êµ­ê°€ë³„ ì„¤ì • ì ìš©)"""
    encoded_query = urllib.parse.quote(query)
    config = REGION_CONFIGS.get(region_code, REGION_CONFIGS['US'])
    
    base_url = f"https://news.google.com/rss/search?q={encoded_query}&hl={config['hl']}&gl={config['gl']}&ceid={config['ceid']}"
    return base_url, config['name']

def fetch_google_rss_items(queries, target_regions=['US'], source_label_prefix="[í•´ì™¸]"):
    """êµ¬ê¸€ RSS ê¸°ë°˜ ë‰´ìŠ¤ ìˆ˜ì§‘ (ë‹¤ì¤‘ êµ­ê°€ ì§€ì›)"""
    items = []
    seen_links = set()
    
    for region in target_regions:
        print(f"ğŸ“¡ {source_label_prefix} ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... (Region: {region})")
        for query in queries:
            url, region_name = get_google_news_rss_url(query, region)
            try:
                feed = feedparser.parse(url)
                # í‚¤ì›Œë“œë³„ ìƒìœ„ ê°œìˆ˜ ì¡°ì ˆ (ë¯¸êµ­ ë¹„ì¤‘ í™•ëŒ€)
                limit = 8 if region == 'US' else 3 
                for entry in feed.entries[:limit]:
                    if entry.link not in seen_links:
                        items.append({
                            "title": entry.title,
                            "link": entry.link,
                            "source": f"{source_label_prefix} {region_name} (Google)",
                            "snippet": entry.get("description", "")[:200]
                        })
                        seen_links.add(entry.link)
            except Exception as e:
                print(f"Error fetching RSS for {query} in {region}: {e}")
            
    return items

def fetch_naver_news():
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ì„¹ì…˜ í¬ë¡¤ë§ (IT/ê³¼í•™, ê²½ì œ)"""
    items = []
    seen_links = set()
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    print("ğŸ“¡ [êµ­ë‚´] ë„¤ì´ë²„ ë‰´ìŠ¤(IT/ê²½ì œ) ìˆ˜ì§‘ ì¤‘...")
    
    for section in NAVER_SECTIONS:
        url = f"https://news.naver.com/section/{section['id']}"
        try:
            response = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            links = soup.find_all("a", href=True)
            
            count = 0
            for link in links:
                href = link['href']
                title = link.get_text(strip=True)
                
                if "/mnews/article/" in href and title and len(title) > 10:
                    if href not in seen_links:
                        items.append({
                            "title": title,
                            "link": href,
                            "source": f"Naver News ({section['name']})",
                            "snippet": "" 
                        })
                        seen_links.add(href)
                        count += 1
                        if count >= 8: # ì„¹ì…˜ë‹¹ ê°œìˆ˜ ì¡°ì ˆ
                            break
        except Exception as e:
            print(f"Naver Fetch Error ({section['name']}): {e}")
            
    return items

def get_usable_model_name():
    """APIì— ì§ì ‘ ë¬¼ì–´ë´ì„œ ì§„ì§œë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={GEMINI_API_KEY}"
    
    try:
        response = requests.get(url)
        if response.status_code != 200:
            print(f"âš ï¸ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {response.text}")
            return None
            
        data = response.json()
        if 'models' not in data:
            print("âš ï¸ ëª¨ë¸ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì°¾ê¸°
        candidates = []
        for model in data['models']:
            name = model['name'].replace('models/', '')
            methods = model.get('supportedGenerationMethods', [])
            
            if 'generateContent' in methods:
                candidates.append(name)
        
        print(f"ğŸ“‹ ë‚´ í‚¤ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëª¨ë¸ë“¤: {candidates}")
        
        preferred = [
            'gemini-1.5-flash',
            'gemini-1.5-flash-latest',
            'gemini-1.5-pro',
            'gemini-1.0-pro',
            'gemini-pro'
        ]
        
        for p in preferred:
            if p in candidates:
                return p
                
        # ì°¨ì„ ì±…
        for c in candidates:
            if 'gemini' in c and 'vision' not in c:
                return c
                
        if candidates:
            return candidates[0]
            
        return None

    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def analyze_news_group(news_items, category_name, limit=10):
    """íŠ¹ì • ê·¸ë£¹(êµ­ë‚´/í•´ì™¸)ì˜ ë‰´ìŠ¤ ì¤‘ Top N ì„ ë³„"""
    if not news_items:
        return []

    print(f"ğŸ§  '{category_name}' ë¶„ì•¼ í›„ë³´ {len(news_items)}ê°œ ë¶„ì„ ë° ì„ ë³„ ì¤‘ (ëª©í‘œ: Top {limit})...")
    
    # ë™ì ìœ¼ë¡œ ëª¨ë¸ ì°¾ê¸°
    model_name = get_usable_model_name()
    if not model_name:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì§€ ëª»í•´ ê¸°ë³¸ê°’(gemini-pro)ìœ¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
        model_name = "gemini-pro"
        
    print(f"âœ¨ ì„ íƒëœ ëª¨ë¸: {model_name}")
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={GEMINI_API_KEY}"
    headers = {'Content-Type': 'application/json'}
    
    # í† í° ì ˆì•½ì„ ìœ„í•œ ê°„ì†Œí™”
    simplified_items = []
    for item in news_items:
        simplified_items.append({
            "t": item['title'],
            "l": item['link'],
            "s": item['source']
        })
        
    news_text = json.dumps(simplified_items, ensure_ascii=False)
    
    prompt = f"""
    ë„ˆëŠ” 'AI/ìŠ¤í¬ì¸  ìŠ¤íƒ€íŠ¸ì—… ë¦¬ì„œì¹˜ íŒ€ì¥'ì´ì•¼.
    ì´ë²ˆ ì‘ì—…ì€ **[{category_name}]** ê´€ë ¨ ë‰´ìŠ¤ ì¤‘ ìš°ë¦¬ì—ê²Œ ê°€ì¥ ê°€ì¹˜ ìˆëŠ” **Top {limit}**ì„ ì„ ì •í•˜ëŠ” ê±°ì•¼.

    [í›„ë³´êµ° ë°ì´í„°]:
    {news_text}

    [ì„ ë³„ ê°€ì´ë“œë¼ì¸]:
    1. **{category_name}** ê´€ì ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì†Œì‹ì„ ìš°ì„ í•´.
    2. **êµ­ë‚´**ì¸ ê²½ìš°: ì •ë¶€ ì •ì±…(ê³¼ê¸°ë¶€/ë¬¸ì²´ë¶€), ëŒ€ê¸°ì—…ì˜ AI/ìŠ¤í¬ì¸  íˆ¬ì, ê·œì œ ì´ìŠˆ ì§‘ì¤‘. (ë‹¨ìˆœ ì •ìŸ/ê°€ì‹­ ì ˆëŒ€ ì œì™¸)
    3. **í•´ì™¸**ì¸ ê²½ìš°: ê¸€ë¡œë²Œ AI íŠ¸ë Œë“œ, ë¹…í…Œí¬ ì›€ì§ì„, í•´ì™¸ ìŠ¤í¬ì¸  ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸. (ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­/ìš”ì•½)
    4. **ê³µí†µ**: ê²½ê¸° ìŠ¤ì½”ì–´, ì—°ì˜ˆì¸ ì´ìŠˆ ì»·.

    [ì‘ì„± ì–‘ì‹]:
    - **ìˆ˜ëŸ‰**: ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ **ì •í™•íˆ {limit}ê°œ** ì¶”ì²œí•´ì¤˜. ë§Œì•½ í›„ë³´ê°€ ë„ˆë¬´ ë¶€ì¡±í•˜ë©´ ìµœì†Œ 3ê°œëŠ” ì„ ì •í•´.
    - **ìˆœì„œ**: ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ê°€ 1ë²ˆì— ì˜¤ë„ë¡ ë°°ì¹˜í•´.
    - **ìš”ì•½**: ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ê°€ ë‹´ê¸´ 1-2ì¤„ ìš”ì•½.

    [ì¶œë ¥ í¬ë§· - JSON Array Only]:
    [
      {{
        "title": "ê¸°ì‚¬ ì œëª©",
        "summary": "í•µì‹¬ ì¸ì‚¬ì´íŠ¸",
        "original_link": "ë§í¬",
        "source": "ì¶œì²˜ í‘œê¸°"
      }}
    ]
    """
    
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            text = response.json().get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '[]')
            clean_text = re.sub(r"```json|```", "", text).strip()
            
            # ë””ë²„ê¹…
            if len(clean_text) < 10:
                print(f"âš ï¸ Gemini ì‘ë‹µì´ ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ìŒ: {clean_text}")

            match = re.search(r'\[.*\]', clean_text, re.DOTALL)
            final_text = match.group(0) if match else clean_text
            
            try:
                return json.loads(final_text)
            except json.JSONDecodeError as je:
                print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ:\n{text}")
                return []
                
        else:
            print(f"Gemini API Error Status: {response.status_code} - {response.text}")
            
    except Exception as e:
        print(f"Gemini API Request Error: {e}")
        return []
    
    return []

def send_discord_report(domestic_list, overseas_list):
    if not DISCORD_WEBHOOK_URL:
        print("ë””ìŠ¤ì½”ë“œ ì›¹í›… URL ì—†ìŒ")
        return
    if not domestic_list and not overseas_list:
        print("ì „ì†¡í•  ë‰´ìŠ¤ê°€ ì•„ì˜ˆ ì—†ìŒ")
        return

    today = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    
    def send_single_embed(title, desc, items, color):
        """ì„ë² ë“œ í•˜ë‚˜ë¥¼ ì „ì†¡í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
        if not items:
            return

        embed = {
            "title": title,
            "description": desc,
            "color": color,
            "fields": [],
            "footer": {
                "text": "Strategy Team Agent via Gemini",
            }
        }
        
        for i, news in enumerate(items):
            # ìš”ì•½ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì „ì†¡ ì˜¤ë¥˜ ë°©ì§€
            summary = news['summary']
            if len(summary) > 300:
                summary = summary[:297] + "..."
            
            # Top 1 ë³„ë„ í‘œê¸°
            is_top_one = (i == 0)
            title_prefix = "â­ [MUST READ] " if is_top_one else "ğŸ”¹ "
            
            value_text = (
                f"**ë¶„ë¥˜**: {news.get('source','[ê¸°íƒ€]')}\n"
                f"**ê¸°ì‚¬ì œëª©**: {news['title']}\n"
                f"**ë‚´ìš©ìš”ì•½**: {summary}\n"
                f"**ì›ë¬¸ë§í¬**: [ğŸ”— ê¸°ì‚¬ ì „ë¬¸ ë³´ê¸°]({news['original_link']})\n"
                f"\u200b" # íˆ¬ëª… ë¬¸ìë¡œ ê°„ê²© í™•ë³´
            )
            
            embed["fields"].append({
                "name": f"{title_prefix} {'TOP 1' if is_top_one else f'News {i+1}'}",
                "value": value_text,
                "inline": False
            })
            
        payload = {"embeds": [embed]}
        
        try:
            response = requests.post(DISCORD_WEBHOOK_URL, json=payload)
            if response.status_code in [200, 204]:
                print(f"âœ… ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì™„ë£Œ: {title}")
            else:
                print(f"âŒ ë””ìŠ¤ì½”ë“œ ì˜¤ë¥˜ ({response.status_code}): {response.text}")
        except Exception as e:
            print(f"ë””ìŠ¤ì½”ë“œ ìš”ì²­ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

    # 1. êµ­ë‚´ íŒŒíŠ¸ ì „ì†¡
    if domestic_list:
        send_single_embed(
            f"ğŸ‡°ğŸ‡· {today} êµ­ë‚´ AI/ìŠ¤í¬ì¸  ì •ì±… & ì‚°ì—…",
            "ì •ë¶€ ì§€ì› ì‚¬ì—… ë° ë„¤ì´ë²„ ë‰´ìŠ¤ ìš”ì•½",
            domestic_list,
            0x00ff00 # Green
        )
        time.sleep(1) # ìˆœì„œ ë³´ì¥ ë° ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€

    # 2. í•´ì™¸ íŒŒíŠ¸ ì „ì†¡
    if overseas_list:
        send_single_embed(
            f"ğŸŒ {today} í•´ì™¸ ê¸€ë¡œë²Œ í…Œí¬ íŠ¸ë Œë“œ",
            "ë¯¸êµ­, ìœ ëŸ½, ì•„ì‹œì•„ ì£¼ìš” ë‰´ìŠ¤ ë²ˆì—­ ë¦¬í¬íŠ¸",
            overseas_list,
            0x3498db # Blue
        )

if __name__ == "__main__":
    # 1. ìˆ˜ì§‘
    
    # 1-1. í•´ì™¸ (ë¯¸êµ­, ìœ ëŸ½, ì¼ë³¸, ì•„ì‹œì•„)
    # ì˜ì–´ ì¿¼ë¦¬ë¥¼ ê°êµ­ êµ¬ê¸€ ë‰´ìŠ¤ì— ë˜ì ¸ì„œ ì§€ì—­ë³„ ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘ (ì¼ë³¸ì€ ì¼ì–´ ê¸°ì‚¬ë„ ì¡í˜)
    overseas_items = fetch_google_rss_items(
        RSS_QUERIES_GLOBAL, 
        target_regions=['US', 'GB', 'JP', 'HK'], 
        source_label_prefix="[í•´ì™¸]"
    )
    
    # 1-2. êµ­ë‚´ ì •ì±… (í•œêµ­ì–´ í‚¤ì›Œë“œ - í•œêµ­ ë¦¬ì „ ê³ ì •)
    # fetch_google_rss_items ì¬í™œìš©
    REGION_CONFIGS['KR'] = {'gl': 'KR', 'hl': 'ko', 'ceid': 'KR:ko', 'name': 'í•œêµ­/ì •ì±…'}
    
    policy_items = fetch_google_rss_items(
        RSS_QUERIES_KR_POLICY, 
        target_regions=['KR'], 
        source_label_prefix="[ì •ì±…]"
    )
    
    # 1-3. êµ­ë‚´ ì¼ë°˜ (ë„¤ì´ë²„ ì„¹ì…˜)
    domestic_items = fetch_naver_news()
    
    # 2. ê·¸ë£¹ë³„ ë¶„ë¦¬ ë° ë¶„ì„
    
    # A. í•´ì™¸ ê·¸ë£¹ (ë¯¸êµ­/ì˜êµ­/ì¼ë³¸/í™ì½©)
    print(f"ğŸ“¦ í•´ì™¸ ë‰´ìŠ¤ í›„ë³´: {len(overseas_items)}ê°œ")
    final_overseas = analyze_news_group(overseas_items, "í•´ì™¸(Global Top 7)", limit=7)

    # B. êµ­ë‚´ ê·¸ë£¹ (ì •ì±… + ë„¤ì´ë²„ ì¼ë°˜)
    domestic_total = policy_items + domestic_items
    print(f"ğŸ“¦ êµ­ë‚´ ë‰´ìŠ¤ í›„ë³´: {len(domestic_total)}ê°œ (ì •ì±… {len(policy_items)} + ì¼ë°˜ {len(domestic_items)})")
    final_domestic = analyze_news_group(domestic_total, "êµ­ë‚´(ì •ì±…/ì‚°ì—… Top 5)", limit=5)
    
    # 3. í†µí•© ë¦¬í¬íŠ¸ ì „ì†¡
    if final_overseas or final_domestic:
        print(f"ğŸ‘‰ ìµœì¢… ì„ ë³„: í•´ì™¸ {len(final_overseas)}ê±´, êµ­ë‚´ {len(final_domestic)}ê±´")
        send_discord_report(final_domestic, final_overseas)
    else:
        print("ğŸ¤” ì„ ë³„ëœ ë‰´ìŠ¤ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
